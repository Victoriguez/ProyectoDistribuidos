# ğŸš¦ AnÃ¡lisis de TrÃ¡fico con Pipeline Distribuido - Entrega 3

**Integrantes:**
- Sebastian Espinoza
- Victor Rodriguez

## ğŸ“‹ DescripciÃ³n General

Este proyecto implementa un **pipeline completo de Big Data** para la ingesta, procesamiento, anÃ¡lisis y visualizaciÃ³n de datos de trÃ¡fico de la plataforma Waze en la RegiÃ³n Metropolitana de Santiago. El sistema transforma datos crudos en insights accionables para la gestiÃ³n de trÃ¡fico utilizando herramientas del ecosistema de Big Data.

### ğŸ¯ Objetivo
Desarrollar una soluciÃ³n end-to-end que permita:
- Recolectar datos de trÃ¡fico en tiempo real desde Waze
- Procesar y enriquecer la informaciÃ³n con datos geoespaciales
- Realizar anÃ¡lisis agregados utilizando Apache Pig
- Almacenar resultados en sistemas de cachÃ© y bÃºsqueda
- Visualizar insights mediante dashboards interactivos

## ğŸ—ï¸ Arquitectura del Sistema

El sistema sigue una **arquitectura de pipeline secuencial** orquestada con Docker Compose:

```
Waze API â†’ Scraper â†’ MongoDB â†’ Mongo Exporter â†’ Apache Pig â†’ Resultados
                                     â†“              â†“
                              Enriquecimiento   AnÃ¡lisis
                                     â†“              â†“
                                   TSV        Redis + Elasticsearch
                                                     â†“
                                                  Kibana
```

### ğŸ“Š Flujo de Datos Detallado

1. **Ingesta**: Scraper Python recolecta alertas de Waze
2. **Almacenamiento**: Datos crudos se guardan en MongoDB
3. **Enriquecimiento**: Python + Shapely aÃ±ade informaciÃ³n geoespacial
4. **Procesamiento**: Apache Pig realiza anÃ¡lisis agregados
5. **CachÃ©**: Redis almacena resultados para acceso rÃ¡pido
6. **IndexaciÃ³n**: Elasticsearch indexa datos para bÃºsquedas
7. **VisualizaciÃ³n**: Kibana presenta dashboards interactivos

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Core Technologies
- **Lenguajes**: Python 3.10, Pig Latin
- **Big Data**: Apache Pig 0.17.0
- **Bases de Datos**: MongoDB 6.0, Redis, Elasticsearch 7.17.10
- **VisualizaciÃ³n**: Kibana 7.17.10
- **OrquestaciÃ³n**: Docker, Docker Compose

### LibrerÃ­as Python
- `requests` - API calls
- `pymongo` - MongoDB integration
- `shapely` - Geospatial processing
- `redis` - Cache management
- `elasticsearch` - Search engine integration

## ğŸ“ Estructura del Proyecto

```
ProyectoDistribuidos/
â”œâ”€â”€ docker-compose.yml                    # OrquestaciÃ³n completa
â”œâ”€â”€ scraper/                             # RecolecciÃ³n de datos
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ scraper.py
â”œâ”€â”€ mongo_exporter/                      # Enriquecimiento de datos
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ export_mongo_to_tsv.py
â”‚   â””â”€â”€ comunas_rm.geojson
â”œâ”€â”€ entrega2/pig_processing/             # Procesamiento con Pig
â”‚   â”œâ”€â”€ Dockerfile.pig
â”‚   â”œâ”€â”€ data_input/                      # waze_events.tsv
â”‚   â”œâ”€â”€ data_output/                     # Resultados de Pig
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ process_waze_data.pig
â”œâ”€â”€ cache_loader/                        # Carga a Redis
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ load_results_to_redis.py
â”œâ”€â”€ es_loader/                           # Carga a Elasticsearch
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ load_to_elasticsearch.py
â””â”€â”€ README.md
```

## ğŸš€ Instrucciones de EjecuciÃ³n

### Prerrequisitos
- Docker Desktop instalado y ejecutÃ¡ndose
- Docker Compose V2
- ConexiÃ³n a internet
- 8GB RAM mÃ­nimo recomendado

### EjecuciÃ³n Completa del Pipeline

1. **Clonar el repositorio**
   ```bash
   git clone <repository-url>
   cd ProyectoDistribuidos
   ```

2. **Limpiar ejecuciones anteriores** (recomendado)
   ```bash
   docker-compose down --remove-orphans
   docker volume prune -f
   ```

3. **Construir e iniciar el pipeline completo**
   ```bash
   docker-compose up --build
   ```

4. **Monitorear el progreso**
   - Los servicios de procesamiento (`scraper`, `mongo_exporter`, `pig_processor`, etc.) se ejecutarÃ¡n secuencialmente
   - Los servicios de infraestructura (`mongodb`, `redis`, `elasticsearch`, `kibana`) permanecerÃ¡n activos

### ğŸ” VerificaciÃ³n de Resultados

#### Verificar datos en MongoDB
```bash
docker exec -it mongodb_container mongosh waze_db --eval "db.eventos.countDocuments()"
```

#### Verificar cache en Redis
```bash
docker exec -it redis_cache_for_pig_results redis-cli
# Dentro de redis-cli:
KEYS stats:*
GET stats:type:CONGESTION
```

#### Verificar Ã­ndices en Elasticsearch
```bash
curl "http://localhost:9200/_cat/indices?v"
```

#### Acceder a Kibana
- URL: http://localhost:5601
- Crear index patterns: `stats_*` y `waze_eventos_procesados`
- Explorar dashboards y visualizaciones

## ğŸ“ˆ Servicios y Componentes

### ğŸ”§ Servicios de Procesamiento

| Servicio | FunciÃ³n | TecnologÃ­a |
|----------|---------|------------|
| `scraper` | RecolecciÃ³n de datos Waze | Python + requests |
| `mongo_exporter` | Enriquecimiento geoespacial | Python + Shapely |
| `pig_processor` | AnÃ¡lisis agregados | Apache Pig 0.17.0 |
| `cache_loader` | Carga a Redis | Python + redis |
| `es_loader` | Carga a Elasticsearch | Python + elasticsearch |

### ğŸ—„ï¸ Servicios de Infraestructura

| Servicio | FunciÃ³n | Puerto | Volumen |
|----------|---------|--------|---------|
| `storage` (MongoDB) | Almacenamiento de datos crudos | 27017 | `mongo_data` |
| `redis_actual_cache` | Cache de resultados | 6379 | `redis_pig_data` |
| `elasticsearch` | Motor de bÃºsqueda | 9200 | `es_data` |
| `kibana` | VisualizaciÃ³n | 5601 | - |

## ğŸ“Š Resultados y AnÃ¡lisis

### MÃ©tricas de Ejemplo (200 eventos)
- **Total eventos procesados**: ~200
- **Comunas identificadas**: 36
- **Tipos de eventos**: 6 categorÃ­as principales

#### DistribuciÃ³n por Tipo de Evento
- CONGESTION: 104 eventos (52%)
- PELIGRO_VIA: 53 eventos (26.5%)
- CORTE_VIAL: 26 eventos (13%)
- CONTROL_POLICIAL: 9 eventos (4.5%)
- ACCIDENTE: 4 eventos (2%)
- OTRO: 4 eventos (2%)

#### Top 5 Comunas por Actividad
1. MaipÃº: 23 eventos
2. Santiago: 21 eventos
3. Las Condes: 18 eventos
4. Ã‘uÃ±oa: 15 eventos
5. Providencia: 12 eventos

#### Patrones Temporales
- **Hora pico**: 21:00 hrs (103 eventos)
- **DÃ­a mÃ¡s activo**: Martes (167 eventos)

## ğŸ”§ Decisiones de DiseÃ±o

### Plan B: Arquitectura PragmÃ¡tica
- **Problema**: Conector mongo-hadoop End-of-Life con MongoDB 6.0
- **SoluciÃ³n**: Enriquecimiento en Python antes del procesamiento en Pig
- **Beneficio**: Mayor robustez y compatibilidad

### Enriquecimiento Geoespacial
- **Herramienta**: Shapely para cÃ¡lculos geomÃ©tricos
- **Datos**: GeoJSON de comunas de la RegiÃ³n Metropolitana
- **Proceso**: Point-in-polygon para determinar comuna por coordenadas

### Rol de Apache Pig
- **FunciÃ³n principal**: Motor de anÃ¡lisis agregado
- **Operaciones**: GROUP BY, SUM, filtrado
- **Salida**: 5 conjuntos de datos agregados

## ğŸš¨ Troubleshooting

### Problemas Comunes

#### Elasticsearch no inicia
```bash
# Verificar vm.max_map_count
docker run --rm --privileged busybox sysctl -w vm.max_map_count=262144
```

#### Puerto ocupado
```bash
# Verificar puertos en uso
netstat -tulpn | grep :9200
# Cambiar puerto en docker-compose.yml si es necesario
```

#### Memoria insuficiente
```bash
# Verificar uso de memoria
docker stats
# Aumentar memoria asignada a Docker Desktop
```

## ğŸ“‹ Logs y Monitoreo

### Revisar logs especÃ­ficos
```bash
# Logs del scraper
docker-compose logs scraper

# Logs de Pig
docker-compose logs pig_processor

# Logs de Elasticsearch
docker-compose logs elasticsearch
```

## ğŸ¯ PrÃ³ximos Pasos

- [ ] Implementar alertas automÃ¡ticas
- [ ] AÃ±adir mÃ¡s fuentes de datos
- [ ] Optimizar rendimiento del pipeline
- [ ] Implementar CI/CD
- [ ] AÃ±adir tests automatizados

## ğŸ“ Contacto

Para consultas sobre el proyecto:
- Sebastian Espinoza: [email]
- Victor Rodriguez: [email]

---

**Nota**: Este proyecto fue desarrollado como parte del curso de Sistemas Distribuidos. La implementaciÃ³n prioriza el aprendizaje de tecnologÃ­as Big Data sobre la optimizaciÃ³n de rendimiento en producciÃ³n.