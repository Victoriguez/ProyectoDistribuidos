# AnÃ¡lisis de TrÃ¡fico con Pipeline Distribuido - Entrega 3

**Integrantes:**
- Sebastian Espinoza
- Victor Rodriguez

## DescripciÃ³n General

Este proyecto implementa un **pipeline completo de Big Data** para la ingesta, procesamiento, anÃ¡lisis y visualizaciÃ³n de datos de trÃ¡fico de la plataforma Waze en la RegiÃ³n Metropolitana de Santiago. El sistema transforma datos crudos en insights accionables para la gestiÃ³n de trÃ¡fico utilizando herramientas del ecosistema de Big Data.

### Objetivo
Desarrollar una soluciÃ³n end-to-end que permita:
- Recolectar datos de trÃ¡fico en tiempo real desde Waze
- Procesar y enriquecer la informaciÃ³n con datos geoespaciales
- Realizar anÃ¡lisis agregados utilizando Apache Pig
- Almacenar resultados en sistemas de cachÃ© y bÃºsqueda
- Visualizar insights mediante dashboards interactivos

## Arquitectura del Sistema

El sistema sigue una **arquitectura de pipeline secuencial** orquestada con Docker Compose:

```
Waze API â†’ Scraper â†’ MongoDB â†’ Mongo Exporter â†’ Apache Pig â†’ Resultados
                                     â†“              â†“
                              Enriquecimiento   AnÃ¡lisis
                                     â†“              â†“
                                   TSV        Redis + Elasticsearch
                                                     â†“
                                                  Kibana
```

### Flujo de Datos Detallado

1. **Ingesta**: Scraper Python recolecta alertas de Waze
2. **Almacenamiento**: Datos crudos se guardan en MongoDB
3. **Enriquecimiento**: Python + Shapely aÃ±ade informaciÃ³n geoespacial
4. **Procesamiento**: Apache Pig realiza anÃ¡lisis agregados
5. **CachÃ©**: Redis almacena resultados para acceso rÃ¡pido
6. **IndexaciÃ³n**: Elasticsearch indexa datos para bÃºsquedas
7. **VisualizaciÃ³n**: Kibana presenta dashboards interactivos

## TecnologÃ­as Utilizadas

### Core Technologies
- **Lenguajes**: Python 3.10, Pig Latin
- **Big Data**: Apache Pig 0.17.0
- **Bases de Datos**: MongoDB 6.0, Redis, Elasticsearch 7.17.10
- **VisualizaciÃ³n**: Kibana 7.17.10
- **OrquestaciÃ³n**: Docker, Docker Compose

### LibrerÃ­as Python
- `requests` - API calls
- `pymongo` - MongoDB integration
- `shapely` - Geospatial processing
- `redis` - Cache management
- `elasticsearch` - Search engine integration

## ğŸ“ Estructura del Proyecto

```
ProyectoDistribuidos/
â”œâ”€â”€ docker-compose.yml                    # OrquestaciÃ³n completa
â”œâ”€â”€ scraper/                             # RecolecciÃ³n de datos
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ scraper.py
â”œâ”€â”€ mongo_exporter/                      # Enriquecimiento de datos
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ export_mongo_to_tsv.py
â”‚   â””â”€â”€ comunas_rm.geojson
â”œâ”€â”€ entrega2/pig_processing/             # Procesamiento con Pig
â”‚   â”œâ”€â”€ Dockerfile.pig
â”‚   â”œâ”€â”€ data_input/                      # waze_events.tsv
â”‚   â”œâ”€â”€ data_output/                     # Resultados de Pig
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ process_waze_data.pig
â”œâ”€â”€ cache_loader/                        # Carga a Redis
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ load_results_to_redis.py
â”œâ”€â”€ es_loader/                           # Carga a Elasticsearch
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ load_to_elasticsearch.py
â””â”€â”€ README.md
```

## Instrucciones de EjecuciÃ³n

### Prerrequisitos
- Docker Desktop instalado y ejecutÃ¡ndose
- Docker Compose V2
- ConexiÃ³n a internet
- 8GB RAM mÃ­nimo recomendado

### EjecuciÃ³n Completa del Pipeline

1. **Clonar el repositorio**
   ```bash
   git clone <https://github.com/Victoriguez/ProyectoDistribuidos.git>
   cd ProyectoDistribuidos
   ```

2. **Limpiar ejecuciones anteriores** (recomendado)
   ```bash
   docker-compose down --remove-orphans
   docker volume prune -f
   ```

3. **Construir e iniciar el pipeline completo**
   ```bash
   docker-compose up --build
   ```

4. **Monitorear el progreso**
   - Los servicios de procesamiento (`scraper`, `mongo_exporter`, `pig_processor`, etc.) se ejecutarÃ¡n secuencialmente
   - Los servicios de infraestructura (`mongodb`, `redis`, `elasticsearch`, `kibana`) permanecerÃ¡n activos

### VerificaciÃ³n de Resultados

#### Verificar datos en MongoDB
```bash
docker exec -it mongodb_container mongosh waze_db --eval "db.eventos.countDocuments()"
```

#### Verificar cache en Redis
```bash
docker exec -it redis_cache_for_pig_results redis-cli
# Dentro de redis-cli:
KEYS stats:*
GET stats:type:CONGESTION
```

#### Verificar Ã­ndices en Elasticsearch
```bash
curl "http://localhost:9200/_cat/indices?v"
```

#### Acceder a Kibana
- URL: http://localhost:5601

## Servicios y Componentes

### Servicios de Procesamiento

| Servicio | FunciÃ³n | TecnologÃ­a |
|----------|---------|------------|
| `scraper` | RecolecciÃ³n de datos Waze | Python + requests |
| `mongo_exporter` | Enriquecimiento geoespacial | Python + Shapely |
| `pig_processor` | AnÃ¡lisis agregados | Apache Pig 0.17.0 |
| `cache_loader` | Carga a Redis | Python + redis |
| `es_loader` | Carga a Elasticsearch | Python + elasticsearch |

### Servicios de Infraestructura

| Servicio | FunciÃ³n | Puerto | Volumen |
|----------|---------|--------|---------|
| `storage` (MongoDB) | Almacenamiento de datos crudos | 27017 | `mongo_data` |
| `redis_actual_cache` | Cache de resultados | 6379 | `redis_pig_data` |
| `elasticsearch` | Motor de bÃºsqueda | 9200 | `es_data` |
| `kibana` | VisualizaciÃ³n | 5601 | - |


## ğŸ”§ Decisiones de DiseÃ±o

### Arquitectura PragmÃ¡tica
- **Problema**: Conector mongo-hadoop End-of-Life con MongoDB 6.0
- **SoluciÃ³n**: Enriquecimiento en Python antes del procesamiento en Pig
- **Beneficio**: Mayor robustez y compatibilidad

### Enriquecimiento Geoespacial
- **Herramienta**: Shapely para cÃ¡lculos geomÃ©tricos
- **Datos**: GeoJSON de comunas de la RegiÃ³n Metropolitana
- **Proceso**: Point-in-polygon para determinar comuna por coordenadas

### Rol de Apache Pig
- **FunciÃ³n principal**: Motor de anÃ¡lisis agregado
- **Operaciones**: GROUP BY, SUM, filtrado
- **Salida**: 5 conjuntos de datos agregados

